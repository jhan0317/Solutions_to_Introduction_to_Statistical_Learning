### Introduction to Satistical Learning Chapter 4

**4.**

**(a)**
10%.

**(b)**
0.1*0.1/1 = 1%.

**(c)**
0.1^100 = 10^-98 %.

**(d)**
As p increase linear, the training obervations will decrease exponentially.

**(e)**

p = 1, length = 0.1

p = 2, length = sqrt(0.1)

p = 3, length = 0.1^(1/3)

p = 100, length = 0.1^(1/100)

**5**

**(a)** Training: QDA. Test: LDA

**(b)** Training & Test: QDA

**(c)** We expect the test accuracy of QDA relative to LDA will improve, because a more flexible method will yield a better fit as more samples can be fit and the variance is offset by large sample size.

**(d)** False, overfitting.

**6.**
y = -6 + 0.05 * x1 + x2

-6 + 2 + 3.5 = - 0.5

p = (e^(-0.5))/(1+e^(-0.5)) = 37.5%

50

**7.**
 75.2%. Textbook P139.
 
**8.**

Since KNN would not misclassify the training set with K = 1. Therefore the actual test error should be 18% * 2 = 36%.

**9.**

27%.

19%.


